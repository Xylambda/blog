{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis from scratch with NumPy and Pandas\n",
    "> In this post, we are going to see the basics of exploratory factor analysis, a key topic of Multivariate Analysis. We will implement a small procedure to extract the factors using Pandas and NumPy.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [factor analysis, numpy, pandas, multivariate analysis]\n",
    "- author: Alejandro Pérez Sanjuán\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my job, in the most recent project I was envolved into, I had to deal with hidden variables. Searching on the web I found a paper that had to solve a similar issue, and they chose to use factor analysis.\n",
    "\n",
    "I honestly knew nothing about factor analysis, so I started to search and read information from different sources. I found that most resources were too opaque, while others didn't explain the concepts in detail and relied its content on explaining the extraction process using libraries such [psych](https://cran.r-project.org/web/packages/psych/index.html) or programs like [SPSS](https://www.ibm.com/analytics/spss-statistics-software).\n",
    "\n",
    "This post aims to solve these problems by explaining the theory (I should say aggregating theory from different sources listed at the end) and then implementing things from scratch. Let's begin!\n",
    "\n",
    "## 1. Theory\n",
    "### 1.1. Definitions\n",
    "Factor analysis is a multivariate method that aims to represent $y_{p}$ observable variables as a linear combination of $f_{m}$ factors, with $m < p$. The factor analysis model can be expressed as follows {% fn 1 %} {% fn 2 %}:\n",
    "\\begin{matrix}\n",
    "   y_{1} - \\mu_{1} = a_{11} f_{1} + a_{12} f_{2} + ... + a_{1m} f_{m} + \\epsilon_{1} \\\\\n",
    "   y_{2} - \\mu_{2} = a_{11} f_{1} + a_{12} f_{2} + ... + a_{1m} f_{m} + \\epsilon_{1} \\\\\n",
    "   \\vdots \\\\\n",
    "   y_{p} - \\mu_{p} = a_{p1} f_{1} + a_{p2} f_{2} + ... + a_{pm} f_{m} + \\epsilon_{p}\n",
    "\\end{matrix}\n",
    "\n",
    "where $\\mu$ is the mean vector, $a_{ij}$ are the loadings and $\\epsilon$ is the error vector. The loadings are nothing more than regression weights for the factors. They can be viewed as the contributions of each factor in estimating the original variables.\n",
    "\n",
    "Why don't we use a simple regression in this case? The answer is pretty obvious: we cannot observe the independent variables, which are the hidden factors.\n",
    "\n",
    "The errors $\\epsilon$ serve to indicate that the hypothesized relationships are not exact {% fn 3 %}. That is, we try to explain the variance of our variables, but we assume we cannot explain all the variance. These errors account for this lack of precision.\n",
    "\n",
    "We can write the factor analysis model in matrix notation:\n",
    "\\begin{equation}\n",
    "Y - \\mu = A \\cdot F + \\varepsilon \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### 1.2. Assumptions\n",
    "The first assumtion is that the existance of these hidden variables is an hypothesis; that is, we cannot assume that these variables really exist.\n",
    "\n",
    "Other assumptions are listed below {% fn 1 %} {% fn 2 %}:\n",
    "* $E[F] = 0$\n",
    "* $cov[F] = E[FF^{T}] = I$, remember $I$ is the identity matrix.\n",
    "* $cov[\\epsilon_{i}, \\epsilon_{j}] = 0$, no association between errors.\n",
    "* $E[\\varepsilon] = 0$\n",
    "* $cov[\\varepsilon] = \\Psi $, where\n",
    "\n",
    "$$\n",
    "\\Psi = \n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "\\Psi_{1} & 0 & ... & 0 \\\\\n",
    "0 & \\Psi_{2} & ... & 0 \\\\\n",
    "0 & 0 & ... & \\Psi_{p} \\\\\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "* $cov(F, \\varepsilon) = 0$, they are independent.\n",
    "\n",
    "### 1.3. Factor extraction.\n",
    "In this post we are only going to see one type of extraction method: principal component. If you work with data, you probably heard these 2 words before. The name for this extraction procedure may be a little misleading but it is true that FA and PCA are related.\n",
    "\n",
    "With this procedure, we try to approximate the covariance/correlation matrix $S$ (they are equal if the data ara standardized) with this expression:\n",
    "$$\n",
    "S \\cong A A^{T} + \\Psi\n",
    "$$\n",
    "\n",
    "$A$ is the loading matrix while $\\Psi$ is the uniqueness matrix. The uniqueness accounts for the proportion of variance that is inherent to each variable and cannot be explain by the factors.\n",
    "\n",
    "### 1.4. Which number of factors should I use?\n",
    "A common criterion to use when deciding the number of factors is the scree plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation\n",
    "For the implementation, we will use `Numpy` and `Pandas`. NumPy will be used to handle almost all calculations while Pandas will take care of keeping the format in a nice and suited way for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with the following dummy data. It is a small matrix on purpose, to make it easier to follow the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kind</th>\n",
       "      <th>Intelligent</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Likeable</th>\n",
       "      <th>Just</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>FSM1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sister</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FSM2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Father</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Teacher</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MSM</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FSM3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Kind  Intelligent  Happy  Likeable  Just\n",
       "FSM1        1            5      5         1     1\n",
       "Sister      8            9      7         9     8\n",
       "FSM2        9            8      9         9     8\n",
       "Father      9            9      9         9     9\n",
       "Teacher     1            9      1         1     9\n",
       "MSM         9            7      7         9     9\n",
       "FSM3        9            7      9         9     7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "a = np.array([[1, 5, 5, 1, 1],\n",
    "              [8, 9, 7, 9, 8],\n",
    "              [9, 8, 9, 9, 8],\n",
    "              [9, 9, 9, 9, 9],\n",
    "              [1, 9, 1, 1, 9],\n",
    "              [9, 7, 7, 9, 9],\n",
    "              [9, 7, 9, 9, 7]])\n",
    "\n",
    "# format\n",
    "columns = ['Kind', 'Intelligent', 'Happy', 'Likeable', 'Just']\n",
    "index = ['FSM1', 'Sister', 'FSM2', 'Father', 'Teacher', 'MSM', 'FSM3']\n",
    "\n",
    "# convert to dataframe\n",
    "data = pd.DataFrame(a, columns=columns, index=index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our factor analysis procedure we will follow [Scikit-Learn](https://scikit-learn.org/stable/) philosophy, which I find very well designed. We will create a class with 2 main public methods: `fit()` and `transform()`. The rest of the methods will serve as helpers of the main functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EFA:\n",
    "    \"\"\"Exploratory factor analysis.\n",
    "    \n",
    "    A class to perform exploratory factor analysis using the\n",
    "    principal component method to extract the factors.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    loadings : pandas.DataFrame\n",
    "        The loadings matrix. Default to None if fit() has not \n",
    "        been called.\n",
    "    communalities : pandas.DataFrame\n",
    "        The communalities matrix. Default to None if fit() has\n",
    "        not been called.\n",
    "    variance_summary : pandas.DataFrame\n",
    "        The variance summary of the data. Default to None if fit()\n",
    "        has not been called.\n",
    "    original_data : pandas.DataFrame\n",
    "        The original data. Deafault to None if 'fit()' has not been\n",
    "        called yet.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_factors : int\n",
    "        The number of factors to extract.\n",
    "    is_corr : bool, optional, default: False\n",
    "        If True, the passed data in 'fit()' must be a correlation matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_factors, is_corr=False):\n",
    "        self.n_factors = n_factors\n",
    "        self.is_corr = is_corr\n",
    "        self.loadings_ = None\n",
    "        self.communalities_ = None\n",
    "        self.variance_summary_ = None\n",
    "    \n",
    "    def fit(self, x):\n",
    "        \"\"\"Fits.\n",
    "        \n",
    "        Fits the factor analysis model and computes loadings, communalities\n",
    "        and uniquenes matrices.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : pandas.DataFrame\n",
    "            The data to fit the model.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        corr_m = self._validate_input(x)\n",
    "\n",
    "        # store data\n",
    "        self.original_data = corr_m\n",
    "        \n",
    "        # Principal factor extraction\n",
    "        self._principal_factor(corr_m)\n",
    "        \n",
    "    def _validate_input(self, x):\n",
    "        \"\"\"Validates input.\n",
    "        \n",
    "        Checks whether the input is appropiate or not.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : pandas.DataFrame\n",
    "            The input to check.\n",
    "        \"\"\"\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise ValueError(\"Please, pass 'x' as pandas.DataFrame\")\n",
    "        \n",
    "        if self.is_corr:\n",
    "            assert len(x) == len(x.columns), \"Data is not symmetric\"\n",
    "            corr_m = x\n",
    "        else:\n",
    "            corr_m = x.corr()\n",
    "        \n",
    "        return corr_m\n",
    "    \n",
    "    def transform(self, x):\n",
    "        \"\"\"Transforms.\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _create_variance_summary(self, w):\n",
    "        \"\"\"Creates variances summary.\n",
    "        \n",
    "        Creates a DataFrame containing the variance summary of\n",
    "        the given data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        w : numpy.array\n",
    "            An array containing the eigenvalues.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Round to 3 decimals\n",
    "        w = np.round(w, 3)\n",
    "        \n",
    "        total = w.sum()\n",
    "        perc_var = np.array([100 * (x/total) for x in w])\n",
    "        \n",
    "        aux_dict = {\"Eigenvalues\": w, \n",
    "                    \"Variance %\": perc_var, \n",
    "                    \"Cum. Variance %\": perc_var.cumsum()}\n",
    "        \n",
    "        self.variance_summary_ = pd.DataFrame(aux_dict,\n",
    "                                             index=self.original_data.index)\n",
    "    \n",
    "    def _principal_factor(self, corr_matrix):\n",
    "        \"\"\"Principal factor procedure\"\"\"\n",
    "        orig_idx = self.original_data.index\n",
    "        \n",
    "        # Singular value decomposition\n",
    "        u, s, v = np.linalg.svd(corr_matrix)\n",
    "        \n",
    "        # compute % of each eigenvalue\n",
    "        self._create_variance_summary(s)\n",
    "        \n",
    "        # Compute loadings and subset them\n",
    "        a = pd.DataFrame(u * np.sqrt(s), index=orig_idx)\n",
    "        self.loadings_ = a.iloc[:, 0:self.n_factors]\n",
    "        \n",
    "        # Compute communalities\n",
    "        self._compute_communalities()\n",
    "        \n",
    "    def _compute_communalities(self):\n",
    "        \"\"\"Computes communalities\"\"\"\n",
    "        orig_idx = self.original_data.index\n",
    "        \n",
    "        # communalities computation\n",
    "        squared_sum = (self.loadings_ ** 2).sum(axis=1)\n",
    "        \n",
    "        # Format dataframe\n",
    "        self.communalities_ = pd.DataFrame(round(squared_sum, 3),\n",
    "                                           index=orig_idx,\n",
    "                                           columns=['Communalities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kind</th>\n",
       "      <th>Intelligent</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Likeable</th>\n",
       "      <th>Just</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kind</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.295536</td>\n",
       "      <td>0.880572</td>\n",
       "      <td>0.995429</td>\n",
       "      <td>0.544567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Intelligent</td>\n",
       "      <td>0.295536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>0.326164</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Happy</td>\n",
       "      <td>0.880572</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.130337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Likeable</td>\n",
       "      <td>0.995429</td>\n",
       "      <td>0.326164</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.544016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Just</td>\n",
       "      <td>0.544567</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.130337</td>\n",
       "      <td>0.544016</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Kind  Intelligent     Happy  Likeable      Just\n",
       "Kind         1.000000     0.295536  0.880572  0.995429  0.544567\n",
       "Intelligent  0.295536     1.000000 -0.021744  0.326164  0.837288\n",
       "Happy        0.880572    -0.021744  1.000000  0.866667  0.130337\n",
       "Likeable     0.995429     0.326164  0.866667  1.000000  0.544016\n",
       "Just         0.544567     0.837288  0.130337  0.544016  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = EFA(n_factors=2, is_corr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eigenvalues</th>\n",
       "      <th>Variance %</th>\n",
       "      <th>Cum. Variance %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kind</td>\n",
       "      <td>3.263</td>\n",
       "      <td>65.26</td>\n",
       "      <td>65.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Intelligent</td>\n",
       "      <td>1.538</td>\n",
       "      <td>30.76</td>\n",
       "      <td>96.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Happy</td>\n",
       "      <td>0.168</td>\n",
       "      <td>3.36</td>\n",
       "      <td>99.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Likeable</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.62</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Just</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Eigenvalues  Variance %  Cum. Variance %\n",
       "Kind               3.263       65.26            65.26\n",
       "Intelligent        1.538       30.76            96.02\n",
       "Happy              0.168        3.36            99.38\n",
       "Likeable           0.031        0.62           100.00\n",
       "Just               0.000        0.00           100.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.variance_summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kind</td>\n",
       "      <td>-0.969455</td>\n",
       "      <td>0.231148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Intelligent</td>\n",
       "      <td>-0.519402</td>\n",
       "      <td>-0.806945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Happy</td>\n",
       "      <td>-0.784517</td>\n",
       "      <td>0.587241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Likeable</td>\n",
       "      <td>-0.970870</td>\n",
       "      <td>0.209949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Just</td>\n",
       "      <td>-0.703964</td>\n",
       "      <td>-0.666927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1\n",
       "Kind        -0.969455  0.231148\n",
       "Intelligent -0.519402 -0.806945\n",
       "Happy       -0.784517  0.587241\n",
       "Likeable    -0.970870  0.209949\n",
       "Just        -0.703964 -0.666927"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Communalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kind</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Intelligent</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Happy</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Likeable</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Just</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Communalities\n",
       "Kind                 0.993\n",
       "Intelligent          0.921\n",
       "Happy                0.960\n",
       "Likeable             0.987\n",
       "Just                 0.940"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.communalities_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "{{ 'C.M Cuadras - Nuevos Métodos de Análisis Multivariante. CMC Editions. Barcelona, 2010 ' | fndetail: 1 }}\n",
    "{{ 'Albin C. Rencher - Methods of Multivariate Analysis. John Wiley & Sons. ' | fndetail: 2 }}\n",
    "{{ 'Peter Tryfos - [Chapter 14: Factor Analysis](http://www.yorku.ca/ptryfos/f1400.pdf)!' | fndetail: 3 }}\n",
    "{{ 'NCSS - [Chapter 420: Factor Analysis](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Factor_Analysis.pdf)!' | fndetail: 4 }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
